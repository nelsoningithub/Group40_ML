{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n",
      "0.20.1+cu118\n",
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import torch\n",
    "import torchvision  # Add this line\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "# Debugging information\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)  \n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device() if torch.cuda.is_available() else 'CPU'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying training files...\n",
      "Copying testing files...\n",
      "Copying testing files2...\n",
      "Dataset split complete.\n",
      "Training files: 6000\n",
      "Testing files: 4000\n",
      "Testing files2: 2477\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = \"./dataset\"\n",
    "NO_WATERMARK_DIR = os.path.join(BASE_DIR, \"no_watermark\")\n",
    "WATERMARKED_DIR = os.path.join(BASE_DIR, \"watermarked\")\n",
    "MASKS_DIR = os.path.join(BASE_DIR, \"masks\")\n",
    "\n",
    "OUTPUT_DIR = \"./dataset_split\"\n",
    "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train1\")\n",
    "TEST_DIR = os.path.join(OUTPUT_DIR, \"test1\")\n",
    "TEST_DIR = os.path.join(OUTPUT_DIR, \"test2\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(TRAIN_DIR, \"no_watermark\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TRAIN_DIR, \"watermarked\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TRAIN_DIR, \"masks\"), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(TEST_DIR, \"no_watermark\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TEST_DIR, \"watermarked\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TEST_DIR, \"masks\"), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(TEST_DIR, \"no_watermark\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TEST_DIR, \"watermarked\"), exist_ok=True)\n",
    "\n",
    "# File names\n",
    "file_names = sorted(os.listdir(NO_WATERMARK_DIR))\n",
    "total_files = len(file_names)\n",
    "\n",
    "# Split sizes\n",
    "TRAIN_SPLIT = 6000  # 6000 for training\n",
    "TEST_SPLIT = 10000  # Remaining 50% for testing\n",
    "\n",
    "train_files = file_names[:TRAIN_SPLIT]\n",
    "test_files = file_names[TRAIN_SPLIT:TEST_SPLIT]\n",
    "test2_files = file_names[TEST_SPLIT:]\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(file_list, src_dir, dest_dir):\n",
    "    for file_name in file_list:\n",
    "        src_path = os.path.join(src_dir, file_name)\n",
    "        dest_path = os.path.join(dest_dir, file_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Copy training files\n",
    "print(\"Copying training files...\")\n",
    "copy_files(train_files, NO_WATERMARK_DIR, os.path.join(TRAIN_DIR, \"no_watermark\"))\n",
    "copy_files(train_files, WATERMARKED_DIR, os.path.join(TRAIN_DIR, \"watermarked\"))\n",
    "copy_files(train_files, MASKS_DIR, os.path.join(TRAIN_DIR, \"masks\"))\n",
    "\n",
    "# Copy testing files (only watermarked and masks)\n",
    "print(\"Copying testing files...\")\n",
    "copy_files(train_files, NO_WATERMARK_DIR, os.path.join(TEST_DIR, \"no_watermark\"))\n",
    "copy_files(test_files, WATERMARKED_DIR, os.path.join(TEST_DIR, \"watermarked\"))\n",
    "copy_files(test_files, MASKS_DIR, os.path.join(TEST_DIR, \"masks\"))\n",
    "\n",
    "print(\"Copying testing files2...\")\n",
    "copy_files(test2_files, NO_WATERMARK_DIR, os.path.join(TEST_DIR, \"no_watermark\"))\n",
    "copy_files(test2_files, WATERMARKED_DIR, os.path.join(TEST_DIR, \"watermarked\"))\n",
    "\n",
    "# Summary\n",
    "print(f\"Dataset split complete.\")\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files: {len(test_files)}\")\n",
    "print(f\"Testing files2: {len(test2_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 6000/6000 [08:19<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 6000/6000 [07:20<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 6000/6000 [07:20<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 6000/6000 [07:19<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 6000/6000 [07:25<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 6000/6000 [07:53<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 6000/6000 [08:03<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 6000/6000 [08:04<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 6000/6000 [07:27<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 6000/6000 [07:31<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 6000/6000 [07:33<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 6000/6000 [07:34<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 6000/6000 [07:32<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 6000/6000 [07:26<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 6000/6000 [07:33<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 6000/6000 [07:45<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 6000/6000 [07:43<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 6000/6000 [07:48<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 6000/6000 [07:50<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 6000/6000 [07:46<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 0.0211\n",
      "Feature Extractor saved.\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "WINDOW_SIZE = 64\n",
    "STRIDE = 32\n",
    "\n",
    "# Dataset paths\n",
    "TRAIN_DIR = \"./dataset_split/train1\"\n",
    "TEST_DIR = \"./dataset_split/test1\"\n",
    "MASK_OUTPUT_DIR = \"./test_mask_results\"\n",
    "os.makedirs(MASK_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Data transformations (no resizing to retain original sizes)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert to tensor while retaining original size\n",
    "])\n",
    "\n",
    "# Custom Dataset\n",
    "class WatermarkSlidingWindowDataset(Dataset):\n",
    "    def __init__(self, watermark_dir, mask_dir, transform=None):\n",
    "        self.watermark_dir = watermark_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.images = sorted(os.listdir(watermark_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        watermark_path = os.path.join(self.watermark_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "\n",
    "        watermark_img = Image.open(watermark_path).convert(\"RGB\")\n",
    "        mask_img = Image.open(mask_path).convert(\"L\")  # Mask is single-channel\n",
    "\n",
    "        original_size = watermark_img.size  # Save original image size (width, height)\n",
    "        filename = self.images[idx]  # Save the filename for reference\n",
    "\n",
    "        if self.transform:\n",
    "            watermark_img = self.transform(watermark_img)\n",
    "            mask_img = self.transform(mask_img)\n",
    "\n",
    "        return watermark_img, mask_img, original_size, filename\n",
    "\n",
    "\n",
    "# Custom collate_fn to handle varying image sizes\n",
    "def collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "# Load training and testing datasets\n",
    "train_dataset = WatermarkSlidingWindowDataset(\n",
    "    watermark_dir=os.path.join(TRAIN_DIR, \"watermarked\"),\n",
    "    mask_dir=os.path.join(TRAIN_DIR, \"masks\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = WatermarkSlidingWindowDataset(\n",
    "    watermark_dir=os.path.join(TEST_DIR, \"watermarked\"),\n",
    "    mask_dir=os.path.join(TEST_DIR, \"masks\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "class UNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNetFeatureExtractor, self).__init__()\n",
    "\n",
    "        # Encoder: Downsampling layers\n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Middle layer\n",
    "        self.middle = self.conv_block(512, 1024, is_middle=True)\n",
    "        \n",
    "        # Decoder: Upsampling layers\n",
    "        self.decoder4 = self.upconv_block(1024, 512)\n",
    "        self.decoder3 = self.upconv_block(512, 256)\n",
    "        self.decoder2 = self.upconv_block(256, 128)\n",
    "        self.decoder1 = self.upconv_block(128, 64)\n",
    "\n",
    "        # Layers to adjust channel dimensions after skip connections\n",
    "        self.conv4 = nn.Conv2d(1024, 512, kernel_size=1)  # Adjust channels\n",
    "        self.conv3 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=1)\n",
    "        self.conv1 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()  # Outputs a mask with values in [0, 1]\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels, is_middle=False):\n",
    "        \"\"\"Helper function to create convolutional blocks, mainly for the encoder and middle layers.\"\"\"\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if not is_middle:\n",
    "            layers.append(nn.MaxPool2d(2))  # Downsample\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Upsampling block in the decoder, using transpose convolution.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding phase\n",
    "        enc1 = self.encoder1(x)  # Output: 64 channels\n",
    "        enc2 = self.encoder2(enc1)  # Output: 128 channels\n",
    "        enc3 = self.encoder3(enc2)  # Output: 256 channels\n",
    "        enc4 = self.encoder4(enc3)  # Output: 512 channels\n",
    "\n",
    "        # Middle layer\n",
    "        middle = self.middle(enc4)  # Output: 1024 channels\n",
    "        \n",
    "        # Decoding phase with skip connections\n",
    "        dec4 = self.decoder4(middle)  # Output: 512 channels\n",
    "        dec4 = F.interpolate(dec4, size=enc4.shape[2:], mode='bilinear', align_corners=False)  # Match size\n",
    "        dec4 = torch.cat([dec4, enc4], dim=1)  # Skip connection\n",
    "        dec4 = self.conv4(dec4)  # Adjust channels\n",
    "\n",
    "        dec3 = self.decoder3(dec4)  # Output: 256 channels\n",
    "        dec3 = F.interpolate(dec3, size=enc3.shape[2:], mode='bilinear', align_corners=False)  # Match size\n",
    "        dec3 = torch.cat([dec3, enc3], dim=1)  # Skip connection\n",
    "        dec3 = self.conv3(dec3)  # Adjust channels\n",
    "\n",
    "        dec2 = self.decoder2(dec3)  # Output: 128 channels\n",
    "        dec2 = F.interpolate(dec2, size=enc2.shape[2:], mode='bilinear', align_corners=False)  # Match size\n",
    "        dec2 = torch.cat([dec2, enc2], dim=1)  # Skip connection\n",
    "        dec2 = self.conv2(dec2)  # Adjust channels\n",
    "\n",
    "        dec1 = self.decoder1(dec2)  # Output: 64 channels\n",
    "        dec1 = F.interpolate(dec1, size=enc1.shape[2:], mode='bilinear', align_corners=False)  # Match size\n",
    "        dec1 = torch.cat([dec1, enc1], dim=1)  # Skip connection\n",
    "        dec1 = self.conv1(dec1)  # Adjust channels\n",
    "\n",
    "        # Final output\n",
    "        out = self.final_conv(dec1)  # Output: 1 channel\n",
    "        out = self.sigmoid(out)  # Mask output with values in [0, 1]\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = UNetFeatureExtractor(in_channels=3, out_channels=1).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        watermarked_imgs, masks, original_sizes, filenames = batch[0]\n",
    "        watermarked_imgs = watermarked_imgs.to(DEVICE).unsqueeze(0)  # Add batch dimension\n",
    "        masks = masks.to(DEVICE).unsqueeze(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        mask_pred = model(watermarked_imgs)\n",
    "        # Resize predicted mask to target size\n",
    "        _, _, target_h, target_w = masks.shape\n",
    "        mask_pred = torch.nn.functional.interpolate(mask_pred, size=(target_h, target_w), mode='bilinear', align_corners=True)\n",
    "        loss = criterion(mask_pred, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "FEATURE_EXTRACTOR_PATH = \"feature_extractor.pth\"\n",
    "torch.save(model.state_dict(), FEATURE_EXTRACTOR_PATH)\n",
    "print(\"Feature Extractor saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seven\\AppData\\Local\\Temp\\ipykernel_14048\\1250631891.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing feature extractor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [01:56<00:00, 34.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All masks generated and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_feature_extractor(test_loader, model_path):\n",
    "    print(\"Testing feature extractor...\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(test_loader)):\n",
    "            # Extract watermarked image, mask, original size, and filename\n",
    "            watermarked_imgs, masks, original_sizes, filenames = batch[0]\n",
    "\n",
    "            # Debug: Print the filename being processed\n",
    "            # print(f\"Processing image: {filenames}\")\n",
    "\n",
    "            watermarked_imgs = watermarked_imgs.to(DEVICE).unsqueeze(0)\n",
    "            mask_pred = model(watermarked_imgs)\n",
    "\n",
    "            # Resize predicted mask to original size\n",
    "            original_size = original_sizes  # (width, height)\n",
    "            filename = filenames\n",
    "\n",
    "            # Extract base name and ensure valid file extension\n",
    "            base_name, ext = os.path.splitext(filename)\n",
    "            if ext.lower() not in [\".jpg\", \".jpeg\", \".png\"]:  # Handle invalid extensions\n",
    "                ext = \".png\"  # Default to PNG if extension is missing or invalid\n",
    "\n",
    "            mask_pred_img = transforms.ToPILImage()(mask_pred.squeeze(0).cpu())\n",
    "            mask_pred_resized = mask_pred_img.resize(original_size, Image.BILINEAR)\n",
    "\n",
    "            # Save predicted mask\n",
    "            output_file = os.path.join(MASK_OUTPUT_DIR, f\"predicted_mask_{base_name}{ext}\")\n",
    "            mask_pred_resized.save(output_file)\n",
    "\n",
    "            # print(f\"Saved mask: {output_file}\")\n",
    "\n",
    "    print(\"All masks generated and saved.\")\n",
    "\n",
    "# Test the feature extractor\n",
    "test_feature_extractor(test_loader, FEATURE_EXTRACTOR_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting second part of training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   5%|▍         | 183/4000 [00:13<04:47, 13.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 176\u001b[0m\n\u001b[0;32m    174\u001b[0m model_part2\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    175\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 176\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader_part2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwatermarked_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwatermarked_imgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwatermarked_imgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add batch dimension\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1191\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m dt \u001b[38;5;241m=\u001b[39m cur_t \u001b[38;5;241m-\u001b[39m last_print_t\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_start_t:\n\u001b[1;32m-> 1191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_print_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m     last_print_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_n\n\u001b[0;32m   1193\u001b[0m     last_print_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1242\u001b[0m, in \u001b[0;36mtqdm.update\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dn(dn)\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dt(dt)\n\u001b[1;32m-> 1242\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlock_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_miniters:\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval \u001b[38;5;129;01mand\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval:\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m-> 1347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1495\u001b[0m, in \u001b[0;36mtqdm.display\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[1;32m-> 1495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:459\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[0;32m    458\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[1;32m--> 459\u001b[0m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:452\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m--> 452\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m     fp_flush()\n",
      "File \u001b[1;32mc:\\Users\\seven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\utils.py:196\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\iostream.py:694\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\iostream.py:590\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     f()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\zmq\\sugar\\socket.py:701\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    695\u001b[0m             data,\n\u001b[0;32m    696\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    697\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    698\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    699\u001b[0m         )\n\u001b[0;32m    700\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_zmq.py:1092\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_zmq.py:1140\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_zmq.py:1339\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_zmq.py:160\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os  # Import the os module\n",
    "import torch\n",
    "import shutil\n",
    "from torch.utils.data import DataLoader, Dataset  # Add Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np  # For numerical operations\n",
    "\n",
    "# Set device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "WINDOW_SIZE = 64\n",
    "STRIDE = 32\n",
    "\n",
    "# Paths\n",
    "MASK_DIR = \"./test_mask_results\"\n",
    "TRAIN_DIR = \"./dataset_split/test1\"\n",
    "TEST_DIR = \"./dataset_split/test2\"\n",
    "OUTPUT_DIR = \"./test_model_result\"\n",
    "\n",
    "# Create output directory for test results\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Data transformations (no resizing to retain original sizes)\n",
    "transform = transforms.Compose([transforms.ToTensor()])  # Convert to tensor while retaining original size\n",
    "\n",
    "# Custom Dataset for second part of training\n",
    "class WatermarkRemovalDataset(Dataset):\n",
    "    def __init__(self, watermarked_dir, mask_dir, transform=None):\n",
    "        self.watermarked_dir = watermarked_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.images = sorted(os.listdir(watermarked_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        watermarked_path = os.path.join(self.watermarked_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, 'predicted_mask_' + self.images[idx])\n",
    "\n",
    "        watermarked_img = Image.open(watermarked_path).convert(\"RGB\")\n",
    "        mask_img = Image.open(mask_path).convert(\"L\")  # Mask is single-channel\n",
    "\n",
    "        original_size = watermarked_img.size  # Save original image size (width, height)\n",
    "        filename = self.images[idx]  # Save the filename for reference\n",
    "\n",
    "        if self.transform:\n",
    "            watermarked_img = self.transform(watermarked_img)\n",
    "            mask_img = self.transform(mask_img)\n",
    "\n",
    "        return watermarked_img, mask_img, original_size, filename\n",
    "\n",
    "\n",
    "# Custom collate_fn to handle varying image sizes\n",
    "def collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "# Load datasets for second part\n",
    "train_dataset_part2 = WatermarkRemovalDataset(\n",
    "    watermarked_dir=os.path.join(TRAIN_DIR, \"watermarked\"),\n",
    "    mask_dir=MASK_DIR,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader_part2 = DataLoader(train_dataset_part2, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Simple UNet-like architecture for second part\n",
    "class UNetForWatermarkRemoval(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNetForWatermarkRemoval, self).__init__()\n",
    "\n",
    "        # Encoder: Downsampling layers\n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Middle layer\n",
    "        self.middle = self.conv_block(512, 1024, is_middle=True)\n",
    "        \n",
    "        # Decoder: Upsampling layers\n",
    "        self.decoder4 = self.upconv_block(1024, 512)\n",
    "        self.decoder3 = self.upconv_block(512, 256)\n",
    "        self.decoder2 = self.upconv_block(256, 128)\n",
    "        self.decoder1 = self.upconv_block(128, 64)\n",
    "\n",
    "        # Layers to adjust channel dimensions after skip connections\n",
    "        self.conv4 = nn.Conv2d(1024, 512, kernel_size=1)  # Adjust channels\n",
    "        self.conv3 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=1)\n",
    "        self.conv1 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        \n",
    "        # Final output layer (3 channels for RGB output)\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels, is_middle=False):\n",
    "        \"\"\"Helper function to create convolutional blocks, mainly for the encoder and middle layers.\"\"\"\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if not is_middle:\n",
    "            layers.append(nn.MaxPool2d(2))  # Downsample\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Upsampling block in the decoder, using transpose convolution.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Combine watermarked image and mask before passing to the network\n",
    "        x = torch.cat([x, mask], dim=1)  # Concatenate along channel dimension\n",
    "\n",
    "        # Encoding phase\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "\n",
    "        # Middle layer\n",
    "        middle = self.middle(enc4)\n",
    "\n",
    "        # Decoding phase with skip connections\n",
    "        dec4 = self.decoder4(middle)\n",
    "        dec4 = F.interpolate(dec4, size=enc4.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
    "        dec4 = self.conv4(dec4)\n",
    "\n",
    "        dec3 = self.decoder3(dec4)\n",
    "        dec3 = F.interpolate(dec3, size=enc3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
    "        dec3 = self.conv3(dec3)\n",
    "\n",
    "        dec2 = self.decoder2(dec3)\n",
    "        dec2 = F.interpolate(dec2, size=enc2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
    "        dec2 = self.conv2(dec2)\n",
    "\n",
    "        dec1 = self.decoder1(dec2)\n",
    "        dec1 = F.interpolate(dec1, size=enc1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
    "        dec1 = self.conv1(dec1)\n",
    "\n",
    "        # Final output\n",
    "        out = self.final_conv(dec1)\n",
    "\n",
    "        # Resize output to match input dimensions\n",
    "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model_part2 = UNetForWatermarkRemoval(in_channels=4, out_channels=3).to(DEVICE)  # In: 3 for image + 1 for mask\n",
    "optimizer_part2 = optim.Adam(model_part2.parameters(), lr=0.0001)\n",
    "criterion_part2 = nn.MSELoss()  # Mean Squared Error Loss (as we are trying to recover the clean image)\n",
    "\n",
    "# Training loop for part 2\n",
    "print(\"Starting second part of training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model_part2.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_loader_part2, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        watermarked_imgs, masks, original_sizes, filenames = batch[0]\n",
    "        watermarked_imgs = watermarked_imgs.to(DEVICE).unsqueeze(0)  # Add batch dimension\n",
    "        masks = masks.to(DEVICE).unsqueeze(0)\n",
    "\n",
    "        optimizer_part2.zero_grad()\n",
    "        cleaned_img_pred = model_part2(watermarked_imgs, masks)  # Predict cleaned image\n",
    "        loss = criterion_part2(cleaned_img_pred, watermarked_imgs)  # Compare to original watermarked image\n",
    "        loss.backward()\n",
    "        optimizer_part2.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss / len(train_loader_part2):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "MODEL_PART2_PATH = \"watermark_removal_model.pth\"\n",
    "torch.save(model_part2.state_dict(), MODEL_PART2_PATH)\n",
    "print(\"Model saved successfully.\")\n",
    "\n",
    "# Testing the model on test2 data\n",
    "model_part2.eval()\n",
    "for batch in tqdm(test_loader_part2, desc=\"Testing the model\"):\n",
    "    with torch.no_grad():\n",
    "        watermarked_imgs, masks, original_sizes, filenames = batch[0]\n",
    "        watermarked_imgs = watermarked_imgs.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        cleaned_img_pred = model_part2(watermarked_imgs, masks)\n",
    "\n",
    "        # Convert tensor to image and save\n",
    "        for i in range(len(filenames)):\n",
    "            cleaned_img_pred_img = cleaned_img_pred[i].cpu().numpy().transpose(1, 2, 0)\n",
    "            cleaned_img_pred_img = (cleaned_img_pred_img * 255).astype(np.uint8)\n",
    "            cleaned_img = Image.fromarray(cleaned_img_pred_img)\n",
    "            cleaned_img.save(os.path.join(OUTPUT_DIR, filenames[i]))  # Save cleaned image\n",
    "\n",
    "print(\"Testing complete and results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
